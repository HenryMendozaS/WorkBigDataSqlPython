# WorkBigDataSqlPython
Estos trabajos son script estandarizados y optimizados para uso profesional con volumenes de Datos - SQL y Python (PySpark - API - SQLAlchemy y Apache Hive -Hadoop) los ETL (Extracción, Transformación y Carga) dentro del contexto de Big Data utilizando SQL y Python. 
Estos ejemplos disponen la posibilidad de resolver problemas en la manipulacion de grandes volumens de datos usando la combinación de SQL y Python junto con frameworks como PySpark, SQLAlchemy y Apache Hive se utilizan para el manejo de Big Data y ETL. Cada uno de estos enfoques es altamente configurable y puede ajustarse según las necesidades específicas de cada proyecto y la infraestructura disponible.

# **Work 1: Extracción y Transformación con SQL y Python **Framworks utilizados: PySpark (Python API para Apache Spark)*
# **Work 2: Carga en SQL utilizando Python  **Framework utilizado: SQLAlchemy (biblioteca para trabajar con bases de datos en Python)*
# **Work 3: Procesamiento en SQL para Análisis de Texto **Framework utilizado: Apache Hive (sistema de almacenamiento y análisis de datos sobre Hadoop)*


